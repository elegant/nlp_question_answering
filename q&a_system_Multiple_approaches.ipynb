{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hjmPHcXReKo"
   },
   "source": [
    "# **Q&A system (Using LangChain)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u28rBDI8IRhE"
   },
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqY-oj2rIDNt"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kwy0veUbZ_9r",
    "outputId": "43dd2261-4b69-4781-acba-8c085bac7685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf -q\n",
    "\n",
    "#wrt Vector db\n",
    "!pip install docarray -q\n",
    "\n",
    "#wrt OpenAI\n",
    "!pip install python-dotenv -q\n",
    "!pip install openai -q #for embeddings\n",
    "!pip install tiktoken -q #for embeddings\n",
    "\n",
    "#wrt LangChain\n",
    "!pip install langchain -q\n",
    "\n",
    "#wrt Gradio\n",
    "!pip install gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36GRfip-VYCS"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader #for loading .pdf file\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "import openai\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "#wrt UI\n",
    "import time\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzjLODmeVbDb"
   },
   "source": [
    "### Config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1fCKaybIqUE"
   },
   "source": [
    "#### API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuKJtAST8Y9a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) #read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47ab5DW_S938"
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAuvEZsvH0AN"
   },
   "outputs": [],
   "source": [
    "def download_pdf(url, output_path):\n",
    "    \"\"\"\n",
    "    download .pdf file from URL & save it at output_path\n",
    "    \"\"\"\n",
    "    urllib.request.urlretrieve(url, output_path)\n",
    "\n",
    "    #or-\n",
    "    #!curl -o paper.pdf https://arxiv.org/pdf/2303.13519.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flDin1hy46Kb"
   },
   "source": [
    "## **UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwWpFJQW45J_"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0)\n",
    "\n",
    "\n",
    "\n",
    "def get_ans(filename, question, model_to_use):\n",
    "  pdf_path = filename\n",
    "  loader = PyPDFLoader(pdf_path)\n",
    "  docs = loader.load_and_split()\n",
    "  db = DocArrayInMemorySearch.from_documents(\n",
    "                                            docs,\n",
    "                                            embeddings\n",
    "                                            )\n",
    "\n",
    "  qa_stuff = RetrievalQA.from_chain_type(\n",
    "                                        retriever=db.as_retriever(),\n",
    "                                        return_source_documents = True,\n",
    "                                        chain_type=\"stuff\",\n",
    "                                        llm=llm,\n",
    "                                        verbose=True\n",
    "                                        )\n",
    "\n",
    "  response = qa_stuff(question) #dict_keys(['query', 'result', 'source_documents'])\n",
    "  answer = response[\"result\"]\n",
    "  context = response[\"source_documents\"]\n",
    "\n",
    "  #formatting context\n",
    "  context = \"\"\n",
    "  for i in range(len(response[\"source_documents\"])):\n",
    "      source_document_path = response[\"source_documents\"][i].metadata[\"source\"]\n",
    "      page_number = str(response[\"source_documents\"][i].metadata[\"page\"])\n",
    "\n",
    "      context += \"\\n\" + \"#\"*50 + \"\\n\"\n",
    "      context += f\"Relevant source text: {source_document_path}, page {page_number}\"+\"\\n\"+\"#\"*50+\"\\n\"\n",
    "      context += response[\"source_documents\"][i].page_content + \"\\n\"\n",
    "\n",
    "  return(answer, context)\n",
    "\n",
    "\n",
    "\n",
    "def question_answer(url, file, question, model_to_use):\n",
    "  start_time = time.perf_counter()\n",
    "\n",
    "  if url.strip() == \"\" and file == None:\n",
    "      return \"[ERROR]: Both URL and PDF is empty. Provide atleast one.\"\n",
    "\n",
    "  if url.strip() != \"\" and file != None:\n",
    "      return \"[ERROR]: Both URL and PDF is provided. Please provide only one (eiter URL or PDF).\"\n",
    "\n",
    "  if question.strip() == \"\":\n",
    "      return \"[ERROR]: Question field is empty\"\n",
    "\n",
    "  if url.strip() != \"\":\n",
    "      glob_url = url\n",
    "      download_pdf(glob_url, \"document.pdf\")\n",
    "      filename=\"document.pdf\"\n",
    "  else:\n",
    "    filename = file.name\n",
    "\n",
    "\n",
    "  answer, context = get_ans(filename, question, model_to_use)\n",
    "\n",
    "  end_time = time.perf_counter()\n",
    "  exec_time = end_time - start_time #second\n",
    "\n",
    "\n",
    "  return(answer, context, exec_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PrZSwtV70eB"
   },
   "outputs": [],
   "source": [
    "title = \"Q&A System\"\n",
    "description = \"This Q&A System allows you to input an entire document & ask questions about its contents. This system has ability to add reference to the specific page number from where the information was found. This adds credibility to the answers generated & also helps you locate the relevant information in the document.\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "  gr.Markdown(f\"<center><h1>{title}</h1></center>\")\n",
    "  gr.Markdown(description)\n",
    "\n",
    "  with gr.Row():\n",
    "\n",
    "    with gr.Group():\n",
    "      url = gr.Textbox(value=\"https://clinicaltrials.gov/ProvidedDocs/00/NCT02415400/Prot_000.pdf\", label='URL')\n",
    "      gr.Markdown(\"<center><h6>or<h6></center>\")\n",
    "      file = gr.File(label='PDF', file_types=['.pdf'])\n",
    "      question = gr.Textbox(value=\"When to perform randomization\", label=\"question (FLAN-T5: Eg- 'question: What is inclusion criteria', 'Summarize: Study Design', 'on full input text: summarize')\")\n",
    "      model_to_use = gr.Dropdown([\"OpenAI\", \"T5\", \"aitextgen\", \"BART\", \"FLAN-T5\"], value=\"OpenAI\", label='model_to_use')\n",
    "      btn = gr.Button(value='Submit')\n",
    "      btn.style(full_width=True)\n",
    "\n",
    "  with gr.Group():\n",
    "      exec_time = gr.Textbox(label='execution time (s)')\n",
    "      answer = gr.Textbox(label='answer')\n",
    "      context = gr.Textbox(label='Relevant chunks within document (Context)')\n",
    "\n",
    "  btn.click(question_answer, inputs=[url, file, question, model_to_use], outputs=[answer, context, exec_time])\n",
    "\n",
    "demo.queue()\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
